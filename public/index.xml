<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Andrej&#39;s thoughts</title>
    <link>https://andleb.netlify.app/</link>
      <atom:link href="https://andleb.netlify.app/index.xml" rel="self" type="application/rss+xml" />
    <description>Andrej&#39;s thoughts</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 01 Jul 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://andleb.netlify.app/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png</url>
      <title>Andrej&#39;s thoughts</title>
      <link>https://andleb.netlify.app/</link>
    </image>
    
    <item>
      <title>A talk on our work on whale communication at the Simons Institute</title>
      <link>https://andleb.netlify.app/post/presentation-of-our-work-on-whale-communication-at-the-simons-institute/</link>
      <pubDate>Sat, 01 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://andleb.netlify.app/post/presentation-of-our-work-on-whale-communication-at-the-simons-institute/</guid>
      <description>&lt;p&gt;I recently helped present our work (together with &lt;a href=&#34;https://twitter.com/BerkeleySCLab&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prof. Gašper Beguš&lt;/a&gt;, &lt;a href=&#34;https://andleb.netlify.app/publication/causalceti/&#34;&gt;paper&lt;/a&gt;)
on the usage of deep generative models for discovering the building blocks of sperm whale communication at the &lt;a href=&#34;https://simons.berkeley.edu/workshops/decoding-communication-nonhuman-species-ii-co-hosted-project-ceti&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Decoding Communication in Nonhuman Species&lt;/em&gt;&lt;/a&gt; symposium hosted
at the &lt;a href=&#34;https://simons.berkeley.edu/homepage&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Simons Institute for the Theory of Computing&lt;/a&gt;, UC Berkeley:&lt;/p&gt;
&lt;br/&gt;
&lt;iframe width=&#34;875&#34; height=&#34;492&#34; src=&#34;https://www.youtube.com/embed/jFo59fDlOho&#34; 
title=&#34;Generative AI and What Is Meaningful Sperm Whale Communication&#34; frameborder=&#34;0&#34; 
allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen&gt;&lt;/iframe&gt;</description>
    </item>
    
    <item>
      <title>Approaching an unknown communication system by latent space exploration and causal inference</title>
      <link>https://andleb.netlify.app/publication/causalceti/</link>
      <pubDate>Mon, 20 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://andleb.netlify.app/publication/causalceti/</guid>
      <description></description>
    </item>
    
    <item>
      <title>New publication: Approaching an unknown communication system</title>
      <link>https://andleb.netlify.app/post/new-publication-approaching-an-unknown-communication-system/</link>
      <pubDate>Mon, 20 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://andleb.netlify.app/post/new-publication-approaching-an-unknown-communication-system/</guid>
      <description>&lt;p&gt;We have a &lt;a href=&#34;https://andleb.netlify.app/publication/causalceti/&#34;&gt;pre-print&lt;/a&gt; out based on our work with &lt;a href=&#34;https://www.projectceti.org/team&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Project CETI&lt;/a&gt;,
an initiative to decipher sperm whale communication using machine learning.&lt;/p&gt;
&lt;p&gt;In the paper, we combine approaches that help discover how known properties of human language are learned by generative models when trained on labeled speech audio data with methodology inspired by causal inference and apply it to the communication system of sperm whales, for which we do not have any such ground truth. With this, we can propose what components of their communication might serve as the carriers of meaning, not only giving credence to existing theories but also suggesting additional ways the whales might encode information.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Diffusion models: an introduction</title>
      <link>https://andleb.netlify.app/post/diffusion-models/</link>
      <pubDate>Sun, 02 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://andleb.netlify.app/post/diffusion-models/</guid>
      <description>


&lt;!-- LaTeX preamble --&gt;
&lt;p&gt;&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  
&lt;/details&gt;
&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Diffusion models seem to have taken the world by storm due to their amazing generative powers. That is not their only
advantage, however. With a bit of a tongue in the proverbial cheek, statistical methods can be traditionally classified
as either inflexible (classical stats), computationally expensive (MCMC), or non-analytical (boosted trees). From this
perspective, &lt;strong&gt;diffusion models&lt;/strong&gt; are a significant outlier since they are extremely flexible, provide access to the full
posterior (and conditional) distributions, and are computationally less expensive than many of the competing methods.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;general-structure&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;General structure&lt;/h2&gt;
&lt;div class=&#34;float&#34;&gt;
&lt;img src=&#34;generative-overview.png&#34; title=&#34;Overview of Generative models&#34; style=&#34;width:70.0%&#34; alt=&#34;An overview of generative models (source)&#34; /&gt;
&lt;div class=&#34;figcaption&#34;&gt;&lt;em&gt;An overview of generative models&lt;/em&gt;
(&lt;a href=&#34;https://lilianweng.github.io/posts/2021-07-11-diffusion-models/&#34;&gt;source&lt;/a&gt;)&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Diffusion models are composed of two separate processes, &lt;strong&gt;the forward&lt;/strong&gt; and &lt;strong&gt;the backward&lt;/strong&gt;.&lt;/p&gt;
&lt;div id=&#34;forward-diffusion&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Forward diffusion&lt;/h3&gt;
&lt;p&gt;In general - a diffusion process can be characterized by a &lt;em&gt;Markov diffusion kernel&lt;/em&gt; given a final state &lt;span class=&#34;math inline&#34;&gt;\(\pi(x)\)&lt;/span&gt;:&lt;/p&gt;
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
    q(x_t | x_{t-1}) = T_\pi(x_t | x_{t-1}; \beta_t)
\end{equation}\]&lt;/span&gt;
&lt;p&gt;Since it’s a length-one Markov process, we have for the full joint: &lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
    q(x_{t=0:T} ) = q(x_0) \prod_{i=1}^T q(x_i | x_{i-1})
\end{equation}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Usually, we use a Gaussian diffusion, for which the posterior is closed form (c.f. the 1-step update in &lt;em&gt;Kalman filtering&lt;/em&gt;):&lt;/p&gt;
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
    q(x_t | x_{t-1}) = \mathcal{N}(\sqrt{1 - \beta_t}x_{t-1}, \beta_t \mathbf{I})
\end{equation}\]&lt;/span&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\beta_i\)&lt;/span&gt;s are called the &lt;strong&gt;variance schedule&lt;/strong&gt;, with usually &lt;span class=&#34;math inline&#34;&gt;\(\beta_1 &amp;lt; \beta_2 &amp;lt; ... &amp;lt; \beta_T\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Moreover, due to the property of the Gaussian distribution:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\alpha_t := 1 - \beta_t\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\bar{\alpha}_t := \prod_{s=1}^t \alpha_t\]&lt;/span&gt;&lt;/p&gt;
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
q(x_t | x_0) = \mathcal{N}(\sqrt{\bar{\alpha_t}}~x_0, (1 - \alpha_t) \mathbf{I}),
\end{equation}\]&lt;/span&gt;
&lt;p&gt;meaning any state in the forward process can be expressed knowing &lt;em&gt;just the initial one&lt;/em&gt; and the &lt;em&gt;variance schedule&lt;/em&gt;. In
general, the theoretical underpinning of &lt;em&gt;Langevin dynamics&lt;/em&gt; guarantees any smooth distribution can be corrupted into
Gaussian noise, meaning the initial distribution can be almost arbitrarily complex, giving the model its expressive power.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;reverse-diffusion&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Reverse diffusion&lt;/h3&gt;
&lt;p&gt;The reverse process is characterized by a new transition probability &lt;span class=&#34;math inline&#34;&gt;\(p(x)\)&lt;/span&gt;.
Its starting point is the stationary distribution at the final time &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;:&lt;/p&gt;
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
    \pi(x_T) := p(x_T)
\end{equation}\]&lt;/span&gt;
&lt;p&gt;Like before:&lt;/p&gt;
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
    p(x_{t=T:0}) = p(x_T) \prod_{i=T-1}^1 p(x_i+1 | x_{i})
\end{equation}\]&lt;/span&gt;
&lt;p&gt;For Gaussian (and binomial), the joint is still in the same family; however, there is no closed-form for the parameters &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\Sigma\)&lt;/span&gt;.
These need to be estimated, in this case via neural networks.&lt;/p&gt;
&lt;p&gt;A natural training target is the likelihood of the original data &lt;span class=&#34;math inline&#34;&gt;\(p(x_0)\)&lt;/span&gt; as given by the learned reverse process’ distribution,
obtained by marginalizing the full joint:
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
    p(x_0) = \int_{\mathcal{X}} p(x_{t=T:0}) ~ dx_1 .... dx_T
\end{equation}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is computationally intractable! A trick is to use annealed importance sampling - comparing the relative probability of the backward - &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; - and the forward trajectories &lt;span class=&#34;math inline&#34;&gt;\(q\)&lt;/span&gt;, where the latter are known in closed form:&lt;/p&gt;
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
    p(x_0) = \int_{\mathcal{X}} q(x_{t=1:T}) ~p(x_T)~ \prod_{t=1}^T \frac{p(x_{t-1}|x_t)}{q(x_{t}|x_{t-1})} ~ dx_1 .... dx_T
\end{equation}\]&lt;/span&gt;
&lt;p&gt;In the limit of very small &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;, both directions become the same.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;training&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Training&lt;/h2&gt;
&lt;p&gt;We maximize the &lt;strong&gt;expected&lt;/strong&gt; log likelihood of the original data &lt;span class=&#34;math inline&#34;&gt;\(p(x_0)\)&lt;/span&gt; under the original true distribution &lt;span class=&#34;math inline&#34;&gt;\(q(x_0)\)&lt;/span&gt;:&lt;/p&gt;
&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
    &amp;amp; L(p, q) = \mathbb{E}_{q(x_0)} [p(x_0)] = \int_{\mathcal{X}} q(x_0) ~ \log p(x_T)~ dx_0\\
    &amp;amp; = -~\mathbb{E}_{q} \left[ \underbrace{D( q(x_T | x_0) || p(x_T))}_{L_T} + \underbrace{\sum_{t=2}^T D( q(x_{t-1} | x_t, x_0) || p(x_{t-1} || x_t))}_{L_{t-1}} - \underbrace{\log p(x_0 | x+1)}_{L_0}   \right]
\end{aligned}\]&lt;/span&gt;
&lt;p&gt;It can be &lt;em&gt;lower bounded&lt;/em&gt; by a closed-form expression:&lt;/p&gt;
&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
    L \geq K = - \sum_{t=2}^T \int q(x_0, x_t) ~ D(q(x_{t-1}|x_{t}, x_{0}) ~||~ p(x_{t-1}|x_{t}))~dx_0,~dx_t\\
    + H_q(X_T|X_0) - H_q(X_1|X_0) - H_p(X_T),&amp;amp;
\end{aligned}\]&lt;/span&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt; is the K-L divergence and H denotes the (conditional) entropies. Hence maximizing the latter maximizes the
former.&lt;/p&gt;
&lt;p&gt;Additionally, conditioning the forward process posteriors on &lt;span class=&#34;math inline&#34;&gt;\(x_0\)&lt;/span&gt; gives us the closed-forms&lt;/p&gt;
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
q(x_{t-1}|x_{t}, x_{0}) = \mathcal{N}(\tilde{\mu}_t, \tilde{\beta}_t \mathbf{I})
\end{equation}\]&lt;/span&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\tilde{\mu}_t := \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t}{1 - \bar{\alpha}_t}~x_0 + \frac{\sqrt{\bar{\alpha}_{t}} (1 - \bar{\alpha}_{t})}{1 - \bar{\alpha}_t}~x_t\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\tilde{\beta}_t := \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \beta_t\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The goal of training is therefore to &lt;strong&gt;estimate the reverse Markov transition densities&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(p(x_{t-1}|x_t)\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[\hat{p}(x_{t-1}|x_t) = \underset{p}{\operatorname{argmax}} K\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;As mentioned, in the case of the Gaussian and binomial, the reverse process stays in the same family, therefore the task amounts to
estimating the parameters.&lt;/p&gt;
&lt;div id=&#34;variance-schedule&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Variance schedule&lt;/h3&gt;
&lt;p&gt;Since &lt;span class=&#34;math inline&#34;&gt;\(\beta_t\)&lt;/span&gt; is a free parameter, it can be learned simultaneously with the whole &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; optimization procedure,
freezing the other variables and optimizing on &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;. Alternatively, the first paper also treated a sequence as a
hyperparameter and used a simply linearly increasing &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;. This is also the approach of &lt;em&gt;Ho et al.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;estimating-p&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Estimating &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Our goal is to learn the following:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
p(x_{t-1} | x_t) = \mathcal{N}(\mu(x_t, t), \Sigma(x_t, t)), ~~ t \in [T, 0]
\]&lt;/span&gt;
which corresponds to estimating &lt;span class=&#34;math inline&#34;&gt;\(\mu(x_t, t), \Sigma(x_t, t)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;For the variance, it is simply set to be isotropic with the diagonal entries either &lt;strong&gt;fixed&lt;/strong&gt; at a constant (either
&lt;span class=&#34;math inline&#34;&gt;\(\beta_t\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(\tilde{\beta}_t\)&lt;/span&gt;) or &lt;strong&gt;learned&lt;/strong&gt;. The latter proved to be unstable in Ho et al., but has since been
successfully implemented.&lt;/p&gt;
&lt;p&gt;The mean is, of course, learned in all implementations and proceeds as follows: by inspecting the &lt;span class=&#34;math inline&#34;&gt;\(L_{t-1}\)&lt;/span&gt; term in the likelihood in &lt;a href=&#34;#training&#34;&gt;Training&lt;/a&gt;, the minimizing mean can be expressed by the reparametrization:
&lt;span class=&#34;math display&#34;&gt;\[x_t = \sqrt{\bar{\alpha}_t}~x_0 + \sqrt{1 - \bar{\alpha}_t}~\epsilon \]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[\epsilon \sim \mathcal{N}(0, \mathbf{I})\]&lt;/span&gt;&lt;/p&gt;
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
\mu(x_t, t) = \frac{1}{\sqrt{\alpha_t}} (x_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha_t}}} \epsilon_{\theta}(x_t, t)),
\end{equation}\]&lt;/span&gt;
&lt;p&gt;meaning we instead learn the estimator of the &lt;strong&gt;noise&lt;/strong&gt; in the mean term at step &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{\theta}(x_t, t))\)&lt;/span&gt; from the state &lt;span class=&#34;math inline&#34;&gt;\(x_t\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;This can be further simplified by setting &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; to be &lt;em&gt;continuous&lt;/em&gt; on &lt;span class=&#34;math inline&#34;&gt;\([1, T]\)&lt;/span&gt; and optimizing the following simplified
objective for &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_\theta(x_t, t)\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
L_{\text{simple}}(\theta) := \mathbb{E}_{t, x_0, \epsilon} \left[\Vert \epsilon - \epsilon_\theta(\sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon, t) \Vert^2\right]
\end{equation}\]&lt;/span&gt; This can be optimized using standard optimization techniques, such as gradient descent. We can now state
the two algorithms needed to first, train the noise estimator &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_\theta\)&lt;/span&gt;, and then, obtain a sample from the
reverse diffusion process: &lt;img src=&#34;ho_algos.png&#34; title=&#34;The two algorithms due to Ho et al.&#34; style=&#34;width:75.0%&#34; alt=&#34;Algorithms due to Ho et al.&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;architecture&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Architecture&lt;/h3&gt;
&lt;p&gt;Ho et al. used a variation of an U-net called &lt;a href=&#34;https://arxiv.org/abs/1701.05517&#34;&gt;PixelCNN++&lt;/a&gt; to estimate
&lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{\theta}(x_t, t))\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class=&#34;float&#34;&gt;
&lt;img src=&#34;u-net-architecture.png&#34; title=&#34;The original U-net&#34; style=&#34;width:50.0%&#34; alt=&#34;The original U-net&#34; /&gt;
&lt;div class=&#34;figcaption&#34;&gt;&lt;em&gt;The original U-net&lt;/em&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;float&#34;&gt;
&lt;img src=&#34;pixelcnn.png&#34; title=&#34;Salimans et al. - PixelCNN++ structure&#34; style=&#34;width:125.0%&#34; alt=&#34;PixelCNN++ structure&#34; /&gt;
&lt;div class=&#34;figcaption&#34;&gt;&lt;em&gt;PixelCNN++ structure&lt;/em&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;how-does-it-work-in-practice&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How does it work in practice?&lt;/h2&gt;
&lt;div id=&#34;example---recovery&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example - recovery&lt;/h3&gt;
&lt;div class=&#34;float&#34;&gt;
&lt;img src=&#34;sohl-dickstein_spiral.png&#34; title=&#34;Spiral distribution recovery&#34; style=&#34;width:80.0%&#34; alt=&#34;Recovery (middle row) of a spiral distribution (top) using a Gaussian diffusion model. The bottom row represents the “drift term”, i.e. the field controlling the mean for the “particles” in the next step of the reverse process.&#34; /&gt;
&lt;div class=&#34;figcaption&#34;&gt;&lt;em&gt;Recovery (middle row) of a spiral distribution (top) using a Gaussian diffusion model. The bottom row represents the
“drift term”, i.e. the field controlling the mean for the “particles” in the next step of the reverse
process.&lt;/em&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;example---generation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example - generation&lt;/h3&gt;
&lt;p&gt;Ho et al. used the modified network for both &lt;strong&gt;conditional&lt;/strong&gt; and &lt;strong&gt;unconditional&lt;/strong&gt; generation.&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;unconditional generation&lt;/em&gt; was performed by estimating &lt;span class=&#34;math inline&#34;&gt;\(x_0\)&lt;/span&gt; - the end result of the reverse process - from
initially random &lt;span class=&#34;math inline&#34;&gt;\(x_T\)&lt;/span&gt;. The following figure shows the order in which features crystallize when the &lt;em&gt;initial state is
itself sampled from various points of the reverse process&lt;/em&gt;. The training dataset was CIFAR10.&lt;/p&gt;
&lt;div class=&#34;float&#34;&gt;
&lt;img src=&#34;ho_uncgen.png&#34; title=&#34;Unconditional generation from the reverse process sample&#34; width=&#34;1500&#34; alt=&#34;Unconditional generation from the reverse process sample&#34; /&gt;
&lt;div class=&#34;figcaption&#34;&gt;&lt;em&gt;Unconditional generation from the reverse process
sample&lt;/em&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;For &lt;em&gt;conditional generation,&lt;/em&gt; the authors selected a &lt;span class=&#34;math inline&#34;&gt;\(x_t\)&lt;/span&gt; from the actual distribution and sampled from the predictive
posterior &lt;span class=&#34;math inline&#34;&gt;\(p(x_0|x_t)\)&lt;/span&gt;. The following figure shows the results conditioned on the bottom-right quadrant, for a network
trained on CelebA-HQ:&lt;/p&gt;
&lt;div class=&#34;float&#34;&gt;
&lt;img src=&#34;ho_condgen.png&#34; title=&#34;Conditional generation samples from a given state&#34; width=&#34;1500&#34; alt=&#34;Conditional generation samples from a given state: the earlier the x_t, the more deterministic the outcome.&#34; /&gt;
&lt;div class=&#34;figcaption&#34;&gt;&lt;em&gt;Conditional generation samples from a given state:&lt;/em&gt; the earlier the &lt;span class=&#34;math inline&#34;&gt;\(x_t\)&lt;/span&gt;, the more deterministic the
outcome.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;imagen-dall-e-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Imagen &amp;amp; DALL-E 2&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2207.12598&#34;&gt;Ho and Salimans&lt;/a&gt; improved the above procedure by introducing the notion of &lt;em&gt;guiding&lt;/em&gt;
the model during training on labeled data, i.e. estimating &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_\theta(x_t, t ∣ y)\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; are the labels. The
crux of the approach is training both on conditional and unconditional objectives at once by randomly setting the class
label to a null class with some predetermined probability. Likewise, the samples are drawn from a convex combination
(with the same coefficient) of both &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-s.&lt;/p&gt;
&lt;p&gt;This was used by Nichol et al. in &lt;a href=&#34;https://arxiv.org/abs/2112.10741?s=09&#34;&gt;GLIDE&lt;/a&gt;, which uses information extracted from
text to do the guiding, combining a transformer with the previously described architecture.&lt;/p&gt;
&lt;p&gt;This approach has been used to construct &lt;a href=&#34;https://arxiv.org/pdf/2205.11487.pdf&#34;&gt;Imagen&lt;/a&gt;, which uses additional diffusion
models to up-sample the image created by the guided diffusion process. The text embeddings are provided by a
&lt;em&gt;pretrained&lt;/em&gt; transformer’s encoder.&lt;/p&gt;
&lt;div class=&#34;float&#34;&gt;
&lt;img src=&#34;imagen.png&#34; width=&#34;700&#34; alt=&#34;Imagen structure&#34; /&gt;
&lt;div class=&#34;figcaption&#34;&gt;&lt;em&gt;Imagen structure&lt;/em&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The other diffusion-based model to make waves recently - DALL-E 2 - uses a bit more complex approach:&lt;/p&gt;
&lt;div class=&#34;float&#34;&gt;
&lt;img src=&#34;dalle2.png&#34; title=&#34;DALL-E 2 architecture&#34; alt=&#34;DALL-E 2 architecture&#34; /&gt;
&lt;div class=&#34;figcaption&#34;&gt;&lt;em&gt;DALL-E 2 architecture&lt;/em&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;First, it re-uses a model called CLIP (Contrastive Language-Image Pre-training) to construct a &lt;em&gt;mapping between captions
and images&lt;/em&gt; (top of the schematic above). In practice, the net result of this is a &lt;em&gt;joint embedding of text and images&lt;/em&gt;
in a representation space.&lt;/p&gt;
&lt;p&gt;In generation, this model is frozen and a version of the GLIDE guided diffusion model is used to generate images
&lt;strong&gt;starting from the image representation space&lt;/strong&gt; (as opposed to random noise, for instance). As previously, additional
up-samplers are used in the decoder, as well.&lt;/p&gt;
&lt;p&gt;To generate from text prompts, we need to map the caption text embeddings to the above mentioned image embeddings, which
are the starting point for the decoder. This is done with an &lt;em&gt;additional diffusion model&lt;/em&gt; called &lt;strong&gt;the prior&lt;/strong&gt;, which
generates &lt;em&gt;multiple possible embeddings.&lt;/em&gt; In other words, this is a generative model of the image embeddings given the
text embeddings. The prior trains a decoder-only transformer to predict the conditional reverse process, as opposed to the U-net
used in other examples.&lt;/p&gt;
&lt;div class=&#34;float&#34;&gt;
&lt;img src=&#34;dalle2_interpolation.png&#34; title=&#34;DALL-E 2: interpolation of the image embedding space&#34; alt=&#34;DALL-E 2: interpolation of the image embedding space by the decoder&#34; /&gt;
&lt;div class=&#34;figcaption&#34;&gt;&lt;em&gt;DALL-E 2: interpolation of the image embedding
space by the decoder&lt;/em&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The original paper: &lt;a href=&#34;https://arxiv.org/abs/1503.03585&#34;&gt;Sohl-Dickstein et al. - Deep Unsupervised Learning using Non-equilibrium
Thermodynamics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Performant implementation: &lt;a href=&#34;https://arxiv.org/abs/2006.11239&#34;&gt;Ho et al. - Denoising Diffusion Probabilistic Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A good blog post: &lt;a href=&#34;https://lilianweng.github.io/posts/2021-07-11-diffusion-models/&#34;&gt;Weng, Lilian. (Jul 2021). What are diffusion models?
Lil’Log.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A summary of recent developments:
&lt;a href=&#34;https://maciejdomagala.github.io/generative_models/2022/06/06/The-recent-rise-of-diffusion-based-models.html&#34; class=&#34;uri&#34;&gt;https://maciejdomagala.github.io/generative_models/2022/06/06/The-recent-rise-of-diffusion-based-models.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;DALL-E 2 initial paper: &lt;a href=&#34;https://arxiv.org/abs/2204.06125&#34;&gt;Ramesh et al. - Hierarchical Text-Conditional Image Generation with CLIP
Latents&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Related:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Kalman_filter&#34;&gt;The Kalman filter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;../../uploads/leban_andrej%20-%20continuous%20time%20kalman%20filter.pdf&#34;&gt;My presentation on the Continuous-time Kalman
filter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1601.00670&#34;&gt;Blei, Kucukelbir, McAuliffe - Variational Inference: A Review for Statisticians&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>New publication, projects</title>
      <link>https://andleb.netlify.app/post/new-publication-projects/</link>
      <pubDate>Sun, 15 May 2022 00:00:00 +0000</pubDate>
      <guid>https://andleb.netlify.app/post/new-publication-projects/</guid>
      <description>&lt;p&gt;Given that the semester&amp;rsquo;s over, I have finally gotten around to updating the site.&lt;/p&gt;
&lt;p&gt;We have a &lt;a href=&#34;https://andleb.netlify.app/publication/bayesiantranslators/&#34;&gt;pre-print&lt;/a&gt; out based on the work I did during my internship last summer.
It examines the problem of inferring the characteristics of different people involved in the process of translating and
reviewing text by using Hierarchical Bayesian Models. Specifically, I came to the idea of using zero-inflated and fat-tailed
distributions to model the number of mistakes; this was influenced both by the statistical properties of the raw data
and by the peculiarities of the process of translation.&lt;/p&gt;
&lt;p&gt;Additionally, I have made public the repositories for two of the final projects I did this year at UC Berkeley:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://andleb.netlify.app/project/ganising/&#34;&gt;ganIsing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://andleb.netlify.app/project/230afinal/&#34;&gt;230Afinal&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(I might make public more in the future&amp;hellip;)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Bayesian approach to translators&#39; reliability assessment</title>
      <link>https://andleb.netlify.app/publication/bayesiantranslators/</link>
      <pubDate>Tue, 12 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://andleb.netlify.app/publication/bayesiantranslators/</guid>
      <description>&lt;p&gt;NOTE: This paper stems from the work I did as a Machine Learning intern at &lt;a href=&#34;https://translated.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Translated&lt;/a&gt;
in Rome during the summer of 2021.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A simple GMAT practice set generator</title>
      <link>https://andleb.netlify.app/post/a-simple-gmat-practice-set-generator/</link>
      <pubDate>Wed, 05 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://andleb.netlify.app/post/a-simple-gmat-practice-set-generator/</guid>
      <description>


&lt;p&gt;&lt;em&gt;NOTE: This is a migration of an old post from my &lt;a href=&#34;https://andleb1.wordpress.com/2020/03/08/a-simple-gmat-practice-set-generator/&#34;&gt;previous blog&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I recently sat for the GMAT. To practice smarter, I came up with a simple &lt;em&gt;Official Guide 2020&lt;/em&gt; problem set generator in Python.
The motivation came from my dissatisfaction with available solutions, for example, the solution you get by registering the book online.
Some don’t allow you to narrow the problems down by sub-category, others aren’t random generators or don’t keep track of done problems.
On the other hand, using my simple generator, you can still input the answers in any online system and thus take advantage of any statistics offered.&lt;/p&gt;
&lt;p&gt;The code and more details at: &lt;a href=&#34;https://github.com/andleb/set_generator&#34; class=&#34;uri&#34;&gt;https://github.com/andleb/set_generator&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to backup git repositories</title>
      <link>https://andleb.netlify.app/post/how-to-backup-git-repositories/</link>
      <pubDate>Wed, 05 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://andleb.netlify.app/post/how-to-backup-git-repositories/</guid>
      <description>


&lt;p&gt;&lt;em&gt;NOTE: This is a migration of an old post from my previous blog.&lt;/em&gt;
&lt;!-- ](https://andleb1.wordpress.com/2019/09/29/how-to-backup-git-repositories/)* --&gt;&lt;/p&gt;
&lt;p&gt;In this post I’d like to briefly sketch my personal setup for git repositories, focusing on their backup.&lt;/p&gt;
&lt;div id=&#34;repository-architecture-overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Repository architecture overview&lt;/h1&gt;
&lt;p&gt;Generally, each repository on my desktop system will have at least two remotes. The first, the ubiquitous &lt;em&gt;origin&lt;/em&gt;, will be located inside an encrypted folder that is mounted inside the &lt;em&gt;Dropbox&lt;/em&gt; directory and hence automatically synced to the cloud. This setup is replicated across all my other machines; its setup could be a topic of a future post.&lt;/p&gt;
&lt;p&gt;The second, which I usually name &lt;em&gt;backup&lt;/em&gt;, is located on a separate hard drive reserved for this purpose. It mirrors the whole repository, which is achieved using:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;git push --mirror backup&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;on the first-time push.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-git-aliases-to-sync-the-backup-on-each-push&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Using git aliases to sync the backup on each push&lt;/h1&gt;
&lt;p&gt;Since this repository is (hopefully) never pulled from, but only kept up to date with an acceptable state of the working repository,
it is therefore convenient to avoid having to push to it manually. For this purpose I set up a &lt;em&gt;git alias&lt;/em&gt; in my &lt;code&gt;.gitconfig&lt;/code&gt;,
which tries to push to all remotes of a particular repository.
In the case of the aforementioned &lt;em&gt;origin&lt;/em&gt;, this command will naturally fail on the occasions where the paths have diverged.
This I let happen and move on, since the motto is &lt;em&gt;“fast–forward if possible”&lt;/em&gt;.
Due to the nature of the &lt;em&gt;backup&lt;/em&gt; repository, however, pushing to it should never fail:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;[alias]
    ...
    pushallbr = !&amp;quot;git remote -v | grep -v &amp;#39;github&amp;#39; | grep -Eo ^\\w+&amp;#39;|\
     xargs -L1 -I R git push R&amp;quot;
    ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;“pushallbr”&lt;/em&gt; stands for &lt;em&gt;“push all branches”&lt;/em&gt;, one can of course pick a different alias.
Note that I filter out &lt;em&gt;github&lt;/em&gt; repositories explicitly (the -v flag in &lt;code&gt;grep&lt;/code&gt; inverts the match).
The purpose of this command is just syncing the local repositories, for the ones on github I want to retain manual control.
In my workflow I usually use this command over the common push origin master and thus sync the backup “automatically”.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;syncing-all-sub-directories&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Syncing all sub-directories&lt;/h1&gt;
&lt;p&gt;Having set up our backup repository and added an alias that syncs it, an useful thing to have would be a shell
script that descends into a hierarchy of repositories and tries to sync them all:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;#! /bin/bash
{find . -maxdepth 8 -type d -exec bash -c &amp;quot;git --git-dir={}/.git --work-tree=$PWD/{} pushallbr&amp;quot; \;} 2&amp;gt;/dev/null
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Things to note:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Since we expect the command to fail in some (or many) cases without adverse side effects,
we ignore the error messages by redirecting them to &lt;code&gt;/dev/null&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;To be able to use a complex git alias within a &lt;code&gt;find ... -exec&lt;/code&gt; command,
one must invoke the whole thing as an inline script via &lt;code&gt;bash -c &#34;...&#34;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How to call all the functions in a Python file on an object</title>
      <link>https://andleb.netlify.app/post/how-to-call-all-the-functions-in-a-python-file-on-an-object/</link>
      <pubDate>Wed, 05 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://andleb.netlify.app/post/how-to-call-all-the-functions-in-a-python-file-on-an-object/</guid>
      <description>


&lt;p&gt;&lt;em&gt;NOTE: This is a migration of an old post from my previous blog.&lt;/em&gt;
&lt;!-- (https://andleb1.wordpress.com/2020/05/28/how-to-call-all-the-functions-in-a-python-file-on-an-object/)* --&gt;&lt;/p&gt;
&lt;p&gt;Recently, I’ve been playing around with some competitions on Kaggle. Given that an inescapable fact of Machine Learning is &lt;em&gt;Feature Selection&lt;/em&gt;,
I’ve been finding myself in the situation of having to call a dozen or more functions that add synthetic features,
infer missing values, etc., on the same &lt;code&gt;Pandas DataFrame&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The following code snippet will call every function in its &lt;code&gt;.py&lt;/code&gt; file but itself on the object,
using tail recursion (nested helper function &lt;code&gt;recCall&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import inspect
import sys
 
import pandas as pd
 
def addAllFeatures(data: pd.DataFrame):
    currFunc  = inspect.getframeinfo(inspect.currentframe()).function
    functions = [obj for name, obj in
                 inspect.getmembers(sys.modules[__name__])
                 if (inspect.isfunction(obj) and name != currFunc)]
 
    def recCall(modifiedData, remFuncs):
        if len(remFuncs) == 0:
            return modifiedData
         
        return recCall(remFuncs[0](modifiedData), remFuncs[1:])
 
    return recCall(data, functions)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For this specific example, the general form of the feature-adding functions is:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;def addFeature(data: pd.DataFrame, *args, **kwargs):
     
    # add the feature ...
     
    return data&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also notable is the fact that the data gets modified between calls of the recursion;
if your features depend on each other, then the &lt;code&gt;functions&lt;/code&gt; list would need to be in the correct dependency order.
Determining this can, however, quickly become non-trivial.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The GitHub’s Arctic Code Vault</title>
      <link>https://andleb.netlify.app/post/the-github-s-arctic-code-vault/</link>
      <pubDate>Wed, 05 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://andleb.netlify.app/post/the-github-s-arctic-code-vault/</guid>
      <description>


&lt;p&gt;&lt;em&gt;NOTE: This is a migration of an old post from my previous blog.&lt;/em&gt;
&lt;!-- https://andleb1.wordpress.com/2020/10/02/the-githubs-arctic-code-vault/)* --&gt;&lt;/p&gt;
&lt;p&gt;Something extremely &lt;em&gt;cool&lt;/em&gt; happened to two of my GitHub repositories (please pardon the pun).
Namely, they were included in Github’s Arctic Vault Archive program.&lt;/p&gt;
&lt;p&gt;In short, GitHub has partnered with a Norwegian company to write some of the repositories to special,
durable film reels and deposit them 250 meters underground in an abandoned coal mine in the remote &lt;a href=&#34;https://en.wikipedia.org/wiki/Svalbard&#34;&gt;Svalbard islands&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;All in all, about 200 3500-foot (1km) reels of film were thus deposited.&lt;/p&gt;
&lt;p&gt;Given how often we hear the familiar complaint of the supposed transience of modern products,
it is uplifting to see a company take a concrete action to remedy this.
As for myself, I am deeply honored to have something that I created preserved for posterity.&lt;/p&gt;
&lt;iframe width=&#34;728&#34; height=&#34;410&#34; src=&#34;https://www.youtube.com/embed/fzI9FNjXQ0o&#34; title=&#34;YouTube video player&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; 
autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>New blog format</title>
      <link>https://andleb.netlify.app/post/new-blog-format/</link>
      <pubDate>Tue, 04 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://andleb.netlify.app/post/new-blog-format/</guid>
      <description>


&lt;p&gt;Since Wordpress was just annoying enough for typesetting math &amp;amp; code to dissuade me from posting regularly, I have decided to migrate to &lt;a href=&#34;https://bookdown.org/yihui/blogdown/&#34;&gt;blogdown&lt;/a&gt;.
&lt;!-- My old blog can be found [here](https://andleb1.wordpress.com/). --&gt;&lt;/p&gt;
&lt;p&gt;I will, however, move over some of the posts there.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ganIsing</title>
      <link>https://andleb.netlify.app/project/ganising/</link>
      <pubDate>Wed, 15 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://andleb.netlify.app/project/ganising/</guid>
      <description>&lt;p&gt;This is my final project for &lt;em&gt;STAT241 / CS281A: Statistical Learning Theory&lt;/em&gt; at UC Berkeley in Fall 2021.&lt;/p&gt;
&lt;p&gt;Given that I&amp;rsquo;ve gotten out of Physics just about when the Deep Learning &amp;ldquo;revolution&amp;rdquo; hit the field, it was a great reason to try in person how generative adversarial networks can replicate results obtained by time-consuming Monte Carlo simulation, something I am deeply familiar with.&lt;/p&gt;
&lt;p&gt;The goal of this project was two-fold: to examine the approach on a classic example - the 2D Ising model, and to provide a brief (the final report linked above was limited to 10 pages) overview of the use of GANs in general.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://andleb.netlify.app/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://andleb.netlify.app/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;span class=&#34;fragment &#34; &gt;
   One 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   **Two** 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   Three 
&lt;/span&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>License</title>
      <link>https://andleb.netlify.app/license/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>https://andleb.netlify.app/license/</guid>
      <description>&lt;p&gt;My &lt;a href=&#34;https://andleb.netlify.app/post/&#34;&gt;blog posts&lt;/a&gt; are released under a &lt;a href=&#34;http://creativecommons.org/licenses/by-sa/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;.&lt;/p&gt;
&lt;center&gt;
&lt;i class=&#34;fab fa-creative-commons fa-2x&#34;&gt;&lt;/i&gt;&lt;i class=&#34;fab fa-creative-commons-by fa-2x&#34;&gt;&lt;/i&gt;&lt;i class=&#34;fab fa-creative-commons-sa fa-2x&#34;&gt;&lt;/i&gt;
&lt;/center&gt;
</description>
    </item>
    
    <item>
      <title>License</title>
      <link>https://andleb.netlify.app/terms/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>https://andleb.netlify.app/terms/</guid>
      <description>&lt;p&gt;My &lt;a href=&#34;https://andleb.netlify.app/post/&#34;&gt;blog posts&lt;/a&gt; are released under a &lt;a href=&#34;http://creativecommons.org/licenses/by-sa/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;.&lt;/p&gt;
&lt;center&gt;
&lt;i class=&#34;fab fa-creative-commons fa-2x&#34;&gt;&lt;/i&gt;&lt;i class=&#34;fab fa-creative-commons-by fa-2x&#34;&gt;&lt;/i&gt;&lt;i class=&#34;fab fa-creative-commons-sa fa-2x&#34;&gt;&lt;/i&gt;
&lt;/center&gt;
</description>
    </item>
    
    <item>
      <title>Example Project</title>
      <link>https://andleb.netlify.app/project/example/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://andleb.netlify.app/project/example/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Time-dependent current through a quantum dot in the presence of a voltage probe</title>
      <link>https://andleb.netlify.app/publication/dipoma/</link>
      <pubDate>Sat, 05 Mar 2016 00:00:00 +0000</pubDate>
      <guid>https://andleb.netlify.app/publication/dipoma/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://andleb.netlify.app/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://andleb.netlify.app/about/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://andleb.netlify.app/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://andleb.netlify.app/admin/config.yml</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://andleb.netlify.app/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://andleb.netlify.app/contact/</guid>
      <description></description>
    </item>
    
    <item>
      <title>230A final</title>
      <link>https://andleb.netlify.app/project/230afinal/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://andleb.netlify.app/project/230afinal/</guid>
      <description>&lt;p&gt;This is my final project for &lt;em&gt;STAT230A: Linear Models&lt;/em&gt; at UC Berkeley in Spring 2022, done jointly with &lt;a href=&#34;https://ischmidt20.github.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Isaac Schmidt&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The goal was to replicate the findings of &lt;a href=&#34;https://www.aeaweb.org/articles?id=10.1257/aer.102.4.1508&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Michalopoulos: The Origins of Ethnolinguistic Diversity&lt;/a&gt;. The project took an additional dimension since we couldn&amp;rsquo;t obtain some of the data used in the paper - the &lt;a href=&#34;https://www.worldgeodatasets.com/language/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WLMS dataset&lt;/a&gt;, prompting us to recreate a portion of the paper using the &lt;a href=&#34;https://icr.ethz.ch/data/greg/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GREG dataset&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The main finding of the paper, which also bore out in our re-analysis using the alternative dataset, is that the &lt;em&gt;variation&lt;/em&gt; in the elevation and in the land quality (see the map above) are the two most decisive factors in driving a region&amp;rsquo;s ethnolinguistic diversity.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>derivatives</title>
      <link>https://andleb.netlify.app/project/derivatives/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://andleb.netlify.app/project/derivatives/</guid>
      <description>&lt;p&gt;A few years back, I undertook a significant study of mathematical finance. I chiefly followed M. Joshi&amp;rsquo;s &lt;a href=&#34;https://www.amazon.com/gp/product/0521514088&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Concepts and Practice of Mathematical Finance&lt;/a&gt; and &lt;a href=&#34;https://www.amazon.com/gp/product/0987122800&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;More Mathematical Finance&lt;/a&gt;.
Since the companion practical textbook, &lt;a href=&#34;https://www.amazon.com/gp/product/0521721628&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;C++ Design Patterns and Derivatives Pricing&lt;/a&gt;,
was based on outdated, pre-&lt;code&gt;C++11&lt;/code&gt; paradigms, and the author has sadly passed away, I decided to rewrite the latter in modern C++.
The goal was to keep the original spirit while adding advanced functionality.
I hope that other people studying from the same sources find the project useful, and I have thus, in a small way, helped keep the book relevant.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Diploma Thesis in Mathematical Physics</title>
      <link>https://andleb.netlify.app/project/diploma/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://andleb.netlify.app/project/diploma/</guid>
      <description>&lt;p&gt;This is the thesis for my Diploma (Master&amp;rsquo;s and Bachelor&amp;rsquo;s combined) in Mathematical Physics at the University of Ljubljana. It was advised by dr. Tomaž Rejec from the Department of Theoretical Physics, Jožef Stefan Institute.&lt;/p&gt;
&lt;p&gt;The work is an original examination of the effects that a coupled voltage probe has on the current flowing through a quantum dot. This was done by numerically simulating the problem from first principles (i.e. from a version of Schrödinger&amp;rsquo;s equation). The main challenge was to ensure that the voltage on the probe was set just so there was no current flowing in or out of it, &lt;em&gt;while&lt;/em&gt; the system was being integrated - i.e. without knowing what the actual currents at that step were.&lt;/p&gt;
&lt;p&gt;The document attached significantly compresses the theoretical background of the thesis (based on the Non-Equilibrium Green&amp;rsquo;s Functions formalism - NEGF), which is to be found in the &lt;a href=&#34;https://journals.aps.org/prb/abstract/10.1103/PhysRevB.72.035308&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;referenced works&lt;/a&gt; since it falls outside of the Diploma program and the recommended Diploma thesis format.&lt;/p&gt;
&lt;p&gt;(&lt;a href=&#34;https://repozitorij.uni-lj.si/IzpisGradiva.php?id=97516&amp;amp;lang=eng&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;University of Ljubljana Repository reference page&lt;/a&gt;)&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
